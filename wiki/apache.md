# Apache Beam

## o que √© o Apache Beam?

O Apache Beam √© um modelo de programa√ß√£o unificado de c√≥digo aberto para pipelines de processamento de dados em lote e em streaming que simplifica a din√¢mica de processamento de dados em grande escala.

### Vantagens ‚úÖ

- √â uma tecnologia vers√°til que oferece suporte as seguintes linguagens de programa√ß√£o: Java, Python, Go
- Conta com uma variedade de executores de pipeline (runners), permitindo que os usu√°rios escolham a melhor op√ß√£o para suas necessidades de execu√ß√£o.
- Capacidade de integrar dados de diversas fontes, proporcionando uma flexibilidade maior no desenvolvimento de pipelines de processamento de dados.

<img width="600" alt="image" src="https://github.com/AnaJuliaMM/pipeline_apache_beam/blob/feature/creating_wiki/wiki/media/apache/beam_img2.png">

## Arquitetura

### 1. Beam SDK (Software Development Kit)

O SDK do Beam, ou Kit de Desenvolvimento de Software do Beam, √© um conjunto de ferramentas e bibliotecas que permite aos desenvolvedores criar pipelines de processamento de dados usando o Apache Beam. Ele fornece APIs para definir fontes de dados, transforma√ß√µes e sa√≠das, al√©m de oferecer suporte para execu√ß√£o em diferentes runners (executores) de pipeline.

### 2. Ferramentas de execu√ß√£o

S√£o os componentes respons√°veis por executar os pipelines de processamento de dados definidos com o Apache Beam. Existem diferentes ferramentas de execu√ß√£o dispon√≠veis, como o Direct Runner (para execu√ß√£o local), o Apache Flink, o Apache Spark, o Google Cloud Dataflow, entre outros.

### 3. Fn Runners

S√£o executores espec√≠ficos para fun√ß√µes (ou "Fn", abrevia√ß√£o de "fun√ß√£o") no Apache Beam. Eles s√£o respons√°veis por executar transforma√ß√µes personalizadas ou fun√ß√µes definidas pelo usu√°rio dentro dos pipelines. Os Fn Runners s√£o usados para execu√ß√£o distribu√≠da de fun√ß√µes em paralelo dentro do ambiente de execu√ß√£o do Apache Beam.

![diagrama](./media/apache/beam_img.png)

## Conceitos

### 1. Pipeline

O Pipeline no Apache Bean encapsula toda a sua tarefa de processamento de dados, do in√≠cio ao fim. Isso inclui a leitura de dados de entrada, a transforma√ß√£o desses dados e a grava√ß√£o de dados de sa√≠da. Todos os programas de driver do Beam devem criar um arquivo Pipeline. Ao criar o Pipeline, voc√™ tamb√©m deve especificar as op√ß√µes de execu√ß√£o que informam Pipelineonde e como executar.

![Pipelines](https://blog.zooxsmart.com/hubfs/imagem-pt-Artigo-de-Blog--Pipeline-de-dados.jpg)

### 2. PCollection

Um "PCollection" representa um conjunto de dados distribu√≠dos no qual o pipeline do Apache Beam opera. Esse conjunto de dados pode ser limitado, originando-se de uma fonte fixa como um arquivo, ou ilimitado, vindo de uma fonte de atualiza√ß√£o cont√≠nua. O pipeline geralmente come√ßa com a cria√ß√£o de um "PCollection" lendo dados de uma fonte externa, mas tamb√©m pode ser criado a partir de dados em mem√≥ria. Os "PCollections" s√£o as entradas e sa√≠das de cada etapa do pipeline.

### 3. PTransform

A "PTransform" representa uma opera√ß√£o de processamento de dados, ou uma etapa, em seu pipeline. Todo "PTransform" recebe um ou mais PCollection objetos como entrada, executa uma fun√ß√£o de processamento que voc√™ fornece nos elementos desse PCollectione produz zero ou mais PCollectionobjetos de sa√≠da.

Ver a execu√ß√£o: üîó

###![Exemplo de Pipeline no Apache Beam](./execucao.md)
Temos um exemplo de pipeline de tranforma√ß√£o de dados, que pega dados JSON e o transforma em CSV.
